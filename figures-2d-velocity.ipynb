{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pickle\n",
    "import yaml\n",
    "import copy\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import scipy.interpolate\n",
    "\n",
    "import cartopy\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "import wandb\n",
    "\n",
    "from dataset import PINNDataset\n",
    "from model import PINN\n",
    "from visualization import GeneratorVisualizationCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use('svg')\n",
    "figure_params = { \"font.family\": 'Times', \"font.size\": 12, \"font.serif\": [], \"svg.fonttype\": 'none'}\n",
    "matplotlib.rcParams.update(figure_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/teisberg/data/common_data/'\n",
    "nc_measure = Dataset(os.path.join(data_dir, 'antarctica_ice_velocity_450m_v2.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_string):\n",
    "    # Download save data\n",
    "    api = wandb.Api()\n",
    "    run = api.run(model_string)\n",
    "    for file in run.files():\n",
    "        if file.name.startswith('gen_model/'):\n",
    "            file.download(root='downloaded_model/', replace=True)\n",
    "        if file.name == 'config.yaml':\n",
    "            file.download(root='downloaded_model/', replace=True)\n",
    "    \n",
    "    # Build model\n",
    "\n",
    "    model_path = 'downloaded_model/gen_model'\n",
    "    parameter_yaml_filename = 'downloaded_model/config.yaml'\n",
    "\n",
    "    #\n",
    "    # Parameters\n",
    "    #\n",
    "\n",
    "    with open(parameter_yaml_filename) as f:\n",
    "        config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        \n",
    "    for k in config:\n",
    "        if isinstance(config[k], dict):\n",
    "            config[k] = config[k]['value']\n",
    "\n",
    "    config['wandb'] = False\n",
    "    #print(config)\n",
    "\n",
    "    #\n",
    "    # Data Loading\n",
    "    #\n",
    "\n",
    "    with open(config['input_data_filename'], 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    dataset = PINNDataset(data, batch_size=config['batch_size'],\n",
    "                            mode=config['mode'], n_random=config['n_random_points'])\n",
    "\n",
    "    #\n",
    "    # Create model\n",
    "    #\n",
    "\n",
    "    model = PINN(config, dataset, gen_model_filename=model_path)\n",
    "    \n",
    "    return config, dataset, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_strings = {\n",
    "    'Cartesian, Symmetric': 'teisberg/igarss2021/1zguuhhe',\n",
    "    'Polar, Asymmetric, Diff Smooth': 'teisberg/igarss2021/1p369fae'\n",
    "}\n",
    "\n",
    "models = {}\n",
    "configs = {}\n",
    "visualizers = {}\n",
    "for k in model_strings:\n",
    "    print(f\"Loading model {k} [{model_strings[k]}]\")\n",
    "    config, dataset, model = load_model(model_strings[k])\n",
    "    viz = GeneratorVisualizationCallback(config, dataset, model)\n",
    "    models[k] = model\n",
    "    configs[k] = config\n",
    "    visualizers[k] = viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = {\n",
    "    'x0': 410000,\n",
    "    'x1': 560000,\n",
    "    'y1': -780000,\n",
    "    'y0': -930000,\n",
    "    'spacing': 500\n",
    "}\n",
    "\n",
    "preds = {}\n",
    "for k in models:\n",
    "    print(f\"Working on {k}\")\n",
    "    roi_x, roi_y, pred = visualizers[k].roi_prediction(roi)\n",
    "    preds[k] = {pk: np.reshape(pred[pk], np.shape(roi_x)) for pk in pred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate surface velocities\n",
    "x = np.array(nc_measure.variables['x'])\n",
    "y = np.array(nc_measure.variables['y'])\n",
    "mask_x = (x > roi['x0']) & (x < roi['x1'])\n",
    "mask_y = (y > roi['y0']) & (y < roi['y1'])\n",
    "measure_X, measure_Y = np.meshgrid(x[mask_x], y[mask_y])\n",
    "measure_vx = np.array(nc_measure.variables['VX'])[mask_y, :][:, mask_x]\n",
    "measure_vy = np.array(nc_measure.variables['VY'])[mask_y, :][:, mask_x]\n",
    "\n",
    "surf_vx = scipy.interpolate.griddata((measure_X.flatten(), measure_Y.flatten()), measure_vx.flatten(),\n",
    "                                   (roi_x, roi_y))\n",
    "surf_vy = scipy.interpolate.griddata((measure_X.flatten(), measure_Y.flatten()), measure_vy.flatten(),\n",
    "                                   (roi_x, roi_y))\n",
    "surf_v = np.sqrt(surf_vx**2 + surf_vy**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_mapping = [\n",
    "#     ('Symmetric Error Bounds', 'Baseline'),\n",
    "#     ('Asymmetric Bounds + Difference Smoothing', 'Velocity Smoothing [- Only]')\n",
    "# ]\n",
    "model_mapping = [(k,k) for k in models]\n",
    "\n",
    "fig, axs = plt.subplots(2, len(model_mapping)+2, figsize=(16,10), sharex=True, sharey=True)\n",
    "\n",
    "norm = matplotlib.colors.Normalize(vmin=0, vmax=500)\n",
    "diff_norm = matplotlib.colors.Normalize(vmin=-50, vmax=50)\n",
    "\n",
    "pcm = axs[0,-2].pcolormesh(roi_x/1000,roi_y/1000,surf_v,norm=norm, rasterized=True, shading='nearest')\n",
    "axs[0,-2].set_aspect('equal')\n",
    "axs[0,-2].set_title('Surface Velocity')\n",
    "\n",
    "for idx, m in enumerate(model_mapping):\n",
    "    k = m[1]\n",
    "    v = np.sqrt(preds[k]['vx']**2 + preds[k]['vy']**2)\n",
    "    pcm = axs[0,idx].pcolormesh(roi_x/1000,roi_y/1000,v,norm=norm, rasterized=True, shading='nearest')\n",
    "    axs[0,idx].set_aspect('equal')\n",
    "    if idx == 0:\n",
    "        clb = fig.colorbar(pcm, ax=axs[0,-1])\n",
    "        clb.set_label('Predicted Depth-Averaged Velocity')\n",
    "    \n",
    "    axs[0,idx].set_title(m[0])\n",
    "    \n",
    "    pcm = axs[1,idx].pcolormesh(roi_x/1000,roi_y/1000,v - surf_v, norm=diff_norm, cmap='coolwarm', rasterized=True, shading='nearest')\n",
    "    axs[1,idx].set_aspect('equal')\n",
    "    if idx == 0:\n",
    "        clb = fig.colorbar(pcm, ax=axs[1,-1])\n",
    "        clb.set_label('Surface - Depth-Averaged Velocity')\n",
    "    \n",
    "    if idx == 0:\n",
    "        axs[0,idx].set_ylabel('Y [km]')\n",
    "        axs[1,idx].set_ylabel('Y [km]')\n",
    "    axs[1,idx].set_xlabel('X [km]')\n",
    "        \n",
    "fig.savefig('figures/raw-vel-comparison-2.svg', format='svg', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf3]",
   "language": "python",
   "name": "conda-env-tf3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
